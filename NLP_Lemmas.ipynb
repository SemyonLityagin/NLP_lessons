{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qR6iTHb2hH9",
        "outputId": "2c59caa8-673b-424f-8144-6080393819d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-23 07:38:04--  https://opencorpora.org/files/export/dict/dict.opcorpora.xml.zip\n",
            "Resolving opencorpora.org (opencorpora.org)... 172.67.163.210, 104.21.15.199, 2606:4700:3030::6815:fc7, ...\n",
            "Connecting to opencorpora.org (opencorpora.org)|172.67.163.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28757314 (27M) [application/zip]\n",
            "Saving to: ‘dict.opcorpora.xml.zip’\n",
            "\n",
            "dict.opcorpora.xml. 100%[===================>]  27.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-09-23 07:38:05 (191 MB/s) - ‘dict.opcorpora.xml.zip’ saved [28757314/28757314]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://opencorpora.org/files/export/dict/dict.opcorpora.xml.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dict.opcorpora.xml.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnrMaULr3v4q",
        "outputId": "111c8140-5d8f-4e0b-fa7a-176d5f8dc95a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dict.opcorpora.xml.zip\n",
            "  inflating: dict.opcorpora.xml      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import re"
      ],
      "metadata": {
        "id": "wJHkOwIu6PYg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocess:\n",
        "    def __init__(self, path_to_xml):\n",
        "        opcorpa_tree = ET.parse(path_to_xml)\n",
        "        opcorpa_tree_root = opcorpa_tree.getroot()\n",
        "\n",
        "        self.gramm_dict = {\n",
        "            \"NOUN\": \"S\",   # существительное\n",
        "            \"NPRO\": \"NI\",  # местоимение-существительное\n",
        "\n",
        "            \"ADJF\": \"A\",   # прилагательное (полное)\n",
        "            \"ADJS\": \"A\",   # прилагательное (краткое)\n",
        "            \"COMP\": \"A\",   # компаратив\n",
        "            \"ADJ\": \"A\",\n",
        "\n",
        "            \"VERB\": \"V\",   # глагол\n",
        "            \"INFN\": \"V\",   # инфинитив\n",
        "            \"GRND\": \"V\",   # деепричастие - глагольная форма\n",
        "            \"PRTF\": \"V\",   # причастие (полное)\n",
        "            \"PRTS\": \"V\",   # причастие (краткое)\n",
        "\n",
        "            \"ADVB\": \"ADV\", # наречие\n",
        "            \"ADV\": \"ADV\", # наречие\n",
        "\n",
        "            \"NUMR\": \"NUM\", # числительное\n",
        "            \"PREP\": \"PR\",  # предлог\n",
        "            \"CONJ\": \"CONJ\",# союз\n",
        "            \"PRCL\": \"PART\",# частица\n",
        "            \"INTJ\": \"INTJ\" # междометие\n",
        "        }\n",
        "        self.pos_gramm = self.gramm_dict.keys()\n",
        "\n",
        "        self.wordform_to_lemma = {}\n",
        "        self.create_detailed_dictionary_(opcorpa_tree_root)\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_word_(word):\n",
        "        return word.strip().lower().replace('ё', 'е')\n",
        "\n",
        "    def create_detailed_dictionary_(self, xml_root):\n",
        "        self.wordform_to_lemma = {}\n",
        "        for lemma in xml_root.findall('.//lemma'):\n",
        "            # пытаемся получить текст леммы\n",
        "            lemma_text = lemma.get('t')\n",
        "            # если не вышло, то берем первую <l ...>\n",
        "            if lemma_text is None:\n",
        "                head = lemma.find('l')\n",
        "                if head is not None:\n",
        "                    lemma_text = head.get('t')\n",
        "\n",
        "                    # собираем все грамм. теги формы\n",
        "                    tags = []\n",
        "                    for g in head.findall('g'):\n",
        "                        v = g.get('v')\n",
        "                        if v:\n",
        "                            tags.append(v.upper())\n",
        "\n",
        "                    # получаем POS\n",
        "                    lemma_pos = \"OTHER\"\n",
        "                    for t in tags:\n",
        "                        if t in self.pos_gramm:\n",
        "                            lemma_pos = self.gramm_dict.get(t, \"OTHER\")\n",
        "                            break\n",
        "                else:\n",
        "                    lemma_text = None\n",
        "            if not lemma_text:\n",
        "                continue\n",
        "\n",
        "            # собираем все <l> (типовая) и все <f> (флексии)\n",
        "            form_nodes = []\n",
        "            form_nodes.extend(lemma.findall('l'))\n",
        "            form_nodes.extend(lemma.findall('f'))\n",
        "\n",
        "            # формируем результат\n",
        "            seen = set()\n",
        "            for form in form_nodes:\n",
        "                wf = form.get('t')\n",
        "                if not wf:\n",
        "                    continue\n",
        "                key = self.normalize_word_(wf)\n",
        "                if (key, lemma_text) in seen:\n",
        "                    continue\n",
        "                seen.add((key, lemma_text))\n",
        "\n",
        "                entry = {'lemma': lemma_text, 'pos': lemma_pos}\n",
        "                if key in self.wordform_to_lemma.keys():\n",
        "                    if entry not in self.wordform_to_lemma[key]:\n",
        "                        self.wordform_to_lemma[key].append(entry)\n",
        "                else:\n",
        "                    self.wordform_to_lemma[key] = [entry]\n",
        "\n",
        "    def pipeline(self, text):\n",
        "        # удаляем знаки\n",
        "        text_without_punctuation = self._delete_punctuation_marks(text)\n",
        "        # разбиваем на слова\n",
        "        words = self._text_to_words(text_without_punctuation)\n",
        "        # получае леммы для слов\n",
        "        results = self._get_words_lemma(words)\n",
        "        return results\n",
        "\n",
        "    @staticmethod\n",
        "    def _delete_punctuation_marks(text):\n",
        "        return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _text_to_words(text):\n",
        "        return [w for w in text.split() if w]\n",
        "\n",
        "    def _get_words_lemma(self, words):\n",
        "        results = []\n",
        "        for word in words:\n",
        "            word_lower = word.lower()\n",
        "            lemmas = self.wordform_to_lemma.get(self.normalize_word_(word))\n",
        "            result = {\n",
        "                \"word\": word,\n",
        "                \"lemmas\": lemmas\n",
        "            }\n",
        "            results.append(result)\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "8fA0zaZ2Gh5D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp = TextPreprocess(\"dict.opcorpora.xml\")"
      ],
      "metadata": {
        "id": "I6qw0eyo_Wl-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ВВЕДИТЕ ЗДЕСЬ ТЕКСТ\n",
        "text = \"Стала стабильнее экономическая и политическая обстановка, предприятия вывели из тени зарплаты сотрудников. Все Гришины одноклассники уже побывали за границей, он был чуть ли не единственным, кого не вывозили никуда дальше Красной Пахры.\"\n",
        "\n",
        "results = tp.pipeline(text)\n",
        "for result in results:\n",
        "    word = result[\"word\"]\n",
        "    lemmas = result[\"lemmas\"]\n",
        "    result_string = word + \"(\"\n",
        "    for idx, lemma in enumerate(lemmas):\n",
        "        result_string += lemma[\"lemma\"] + \"=\" + lemma[\"pos\"]\n",
        "        result_string += \",\" if idx != len(lemmas)-1 else \"\"\n",
        "    result_string += \")\"\n",
        "    print(result_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqLHNvBLFX-O",
        "outputId": "fc93c37e-1314-4e3b-fd19-af5bb2f25653"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Стала(стал=V)\n",
            "стабильнее(стабильнее=A)\n",
            "экономическая(экономический=A)\n",
            "и(и=CONJ,и=INTJ,и=PART,и=S)\n",
            "политическая(политический=A)\n",
            "обстановка(обстановка=S)\n",
            "предприятия(предприятие=S)\n",
            "вывели(вывел=V)\n",
            "из(из=PR,иза=S)\n",
            "тени(теню=V,тень=S)\n",
            "зарплаты(зарплата=S)\n",
            "сотрудников(сотрудник=S)\n",
            "Все(весь=A,всё=PART)\n",
            "Гришины(гришины=S,гришин=A)\n",
            "одноклассники(одноклассник=S)\n",
            "уже(уж=S,уже=ADV,уже=A,уже=PART)\n",
            "побывали(побывал=V)\n",
            "за(за=PR)\n",
            "границей(граница=S)\n",
            "он(он=NI)\n",
            "был(есть=V)\n",
            "чуть(чуть=ADV,чуть=CONJ)\n",
            "ли(ли=CONJ,ли=PART,ли=S)\n",
            "не(не=PART)\n",
            "единственным(единственный=A)\n",
            "кого(кто=NI)\n",
            "не(не=PART)\n",
            "вывозили(вывожу=V,вывозил=V)\n",
            "никуда(никуда=ADV)\n",
            "дальше(дальше=A)\n",
            "Красной(красная=S,красный=A)\n",
            "Пахры(пахра=S)\n"
          ]
        }
      ]
    }
  ]
}